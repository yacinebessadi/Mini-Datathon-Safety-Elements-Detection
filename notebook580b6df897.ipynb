{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":93136,"databundleVersionId":11091933,"sourceType":"competition"},{"sourceId":465838,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":375838,"modelId":396609}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom collections import Counter\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:38:45.309573Z","iopub.execute_input":"2025-07-16T20:38:45.309945Z","iopub.status.idle":"2025-07-16T20:38:45.316118Z","shell.execute_reply.started":"2025-07-16T20:38:45.309917Z","shell.execute_reply":"2025-07-16T20:38:45.314795Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\n\nimage_dir = '/kaggle/input/draft-safety/train/train_safety'\ncsv_path = \"/kaggle/input/draft-safety/train/train_annotation.csv\"\n\ndf = pd.read_csv(csv_path)\n\nfor image_name in os.listdir(image_dir):\n    if image_name.endswith('.jpg'):\n        image_id = image_name.replace('.jpg', '')\n        labels = df[df['image_id'] == image_id]['labels'].values[0]\n        img_path = os.path.join(image_dir, image_name)\n        image = Image.open(img_path)\n\n        #print(f\"\\nImage: {image_name}\")\n        #print(f\"Size: {image.size}\")\n        #print(f\"Labels: {labels}\")\n\n        # Optional: Show first 3 images\n        '''if os.listdir(image_dir).index(image_name) < 3:\n            image.show()'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:38:45.318431Z","iopub.execute_input":"2025-07-16T20:38:45.318764Z","iopub.status.idle":"2025-07-16T20:39:04.439911Z","shell.execute_reply.started":"2025-07-16T20:38:45.318738Z","shell.execute_reply":"2025-07-16T20:39:04.438997Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\nall_labels = ['person', 'red_hat', 'yellow_hat', 'blue_hat', 'vest', 'white_hat']\ndf['label_list'] = df['labels'].str.split()\n\nmlb = MultiLabelBinarizer(classes=all_labels)\nbinary_labels = mlb.fit_transform(df['label_list'])\nprint(binary_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:39:04.440873Z","iopub.execute_input":"2025-07-16T20:39:04.441189Z","iopub.status.idle":"2025-07-16T20:39:04.458480Z","shell.execute_reply.started":"2025-07-16T20:39:04.441155Z","shell.execute_reply":"2025-07-16T20:39:04.457769Z"}},"outputs":[{"name":"stdout","text":"[[1 1 1 0 0 0]\n [1 0 0 1 0 0]\n [1 0 1 0 1 0]\n ...\n [1 0 0 0 1 1]\n [1 1 0 0 0 0]\n [1 1 1 0 0 1]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"image_sizes=[]\nfor img_name in os.listdir(image_dir):\n    if img_name.endswith(\".jpg\"):\n        img_path = os.path.join(image_dir, img_name)\n        with Image.open(img_path) as img:\n            image_sizes.append(img.size)\n\noutput_dir = '/kaggle/working/resized_images'\nos.makedirs(output_dir, exist_ok=True)\n\ntarget_size = (224, 224)\n\nfor img_name in os.listdir(image_dir):\n    if img_name.endswith('.jpg'):\n        img_path = os.path.join(image_dir, img_name)\n        img = Image.open(img_path)\n        img_resized = img.resize(target_size)\n        img_resized.save(os.path.join(output_dir, img_name))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:39:04.459351Z","iopub.execute_input":"2025-07-16T20:39:04.459734Z","iopub.status.idle":"2025-07-16T20:40:03.474424Z","shell.execute_reply.started":"2025-07-16T20:39:04.459699Z","shell.execute_reply":"2025-07-16T20:40:03.473384Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as T\nfrom PIL import Image\nimport os\n\nclass SafetyDataset(Dataset):\n    def __init__(self, df, image_dir, labels=None, transform=None):\n        self.df = df\n        self.image_dir = image_dir\n        self.labels = labels  # Labels can be None for test dataset\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        image_id = self.df.iloc[index]['image_id']  # Get image ID\n        img_path = os.path.join(self.image_dir, f\"{image_id}.jpg\")  # Build image path\n        image = Image.open(img_path).convert('RGB')  # Open image\n\n        if self.transform:\n            image = self.transform(image)  # Apply transformations\n\n        # Handle case where labels are None (test dataset)\n        if self.labels is not None:\n            label = torch.tensor(self.labels[index]).float()  # Convert labels to tensor\n            return image, label\n        else:\n            return image, image_id  # Return image and image_id for test dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:40:03.476827Z","iopub.execute_input":"2025-07-16T20:40:03.477201Z","iopub.status.idle":"2025-07-16T20:40:16.000898Z","shell.execute_reply.started":"2025-07-16T20:40:03.477173Z","shell.execute_reply":"2025-07-16T20:40:15.999774Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torchvision import transforms\n\n# This is the transform object we are modifying\ntransform = transforms.Compose([\n    # --- ADD DATA AUGMENTATION HERE ---\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    # --- END OF AUGMENTATION ---\n    \n    transforms.ToTensor(),  # convert image to tensor with shape [C, H, W] and scale to [0, 1]\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # normalize RGB values\n])\n\ndataset = SafetyDataset(df, '/kaggle/working/resized_images', binary_labels, transform=transform)\nimg,lbl=dataset[0]\nprint(img.shape,lbl)\nprint(\"Original:\", df.iloc[0]['labels'])\nprint(\"Binary:  \", labels[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:40:16.001729Z","iopub.execute_input":"2025-07-16T20:40:16.002141Z","iopub.status.idle":"2025-07-16T20:40:16.055928Z","shell.execute_reply.started":"2025-07-16T20:40:16.002116Z","shell.execute_reply":"2025-07-16T20:40:16.054890Z"}},"outputs":[{"name":"stdout","text":"torch.Size([3, 224, 224]) tensor([1., 1., 1., 0., 0., 0.])\nOriginal: person red_hat yellow_hat\nBinary:   p\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ndataloader=DataLoader(dataset,batch_size=32,shuffle=True)\nfor images, labels in dataloader:\n    print(\"Image batch shape:\", images.shape)   # Should be [32, 3, 224, 224]\n    print(\"Label batch shape:\", labels.shape)   # Should be [32, 6]\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:40:16.057009Z","iopub.execute_input":"2025-07-16T20:40:16.057345Z","iopub.status.idle":"2025-07-16T20:40:16.279201Z","shell.execute_reply.started":"2025-07-16T20:40:16.057316Z","shell.execute_reply":"2025-07-16T20:40:16.277931Z"}},"outputs":[{"name":"stdout","text":"Image batch shape: torch.Size([32, 3, 224, 224])\nLabel batch shape: torch.Size([32, 6])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, temp_df, train_labels, temp_labels = train_test_split(\n    df, binary_labels, test_size=0.3, random_state=42)\n#split temp into validation and test \nval_df, test_df, val_labels, test_labels = train_test_split(\n    temp_df, temp_labels, test_size=0.5, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:40:16.280851Z","iopub.execute_input":"2025-07-16T20:40:16.281157Z","iopub.status.idle":"2025-07-16T20:40:16.421026Z","shell.execute_reply.started":"2025-07-16T20:40:16.281129Z","shell.execute_reply":"2025-07-16T20:40:16.420035Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Import PyTorch's neural network module\nimport torch.nn as nn\n\n# Define a class called SafetyCNN, which is your model\nclass SafetyCNN(nn.Module):\n    def __init__(self):\n        # Call the parent class constructor\n        super(SafetyCNN, self).__init__()\n\n        # üîπ 1st Convolution Layer: input image with 3 channels (RGB), output 16 feature maps\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(2, 2)  # Downsample (reduce) the image by half\n\n        # üîπ 2nd Convolution Layer: from 16 input channels to 32\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(2, 2)\n        nn.BatchNorm2d(16),  # After Conv2d(3, 16, ...)\n\n        # üîπ 3rd Convolution Layer: from 32 input channels to 64\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        self.relu3 = nn.ReLU()\n        self.pool3 = nn.MaxPool2d(2, 2)\n\n        nn.Conv2d(64, 128, 3, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),\n\n        # üîπ Flatten the output into a single long vector so we can use a fully connected layer\n        self.flatten = nn.Flatten()\n        nn.Dropout(0.5),  # Apply before the Linear layer\n\n        # üîπ Fully connected layer: input is 64 * 28 * 28 (after all the pooling), output is 6 values (for 6 labels)\n        self.fc = nn.Linear(64 * 28 * 28, 6)\n\n        # üîπ Sigmoid activation: gives 6 values between 0 and 1 (multi-label probabilities)\n        self.sigmoid = nn.Sigmoid()\n\n    # üîÅ Forward function: tells PyTorch how to pass input through the model\n    def forward(self, x):\n        #print(f\"[Input]         {x.shape}\")\n\n        x = self.pool1(self.relu1(self.conv1(x)))\n        #print(f\"[After Conv1]   {x.shape}\")\n\n        x = self.pool2(self.relu2(self.conv2(x)))\n       # print(f\"[After Conv2]   {x.shape}\")\n\n        x = self.pool3(self.relu3(self.conv3(x)))\n        #print(f\"[After Conv3]   {x.shape}\")\n\n        x = self.flatten(x)\n        #print(f\"[After Flatten] {x.shape}\")\n\n        x = self.fc(x)\n       # print(f\"[After FC]      {x.shape}\")\n\n        x = self.sigmoid(x)\n       # print(f\"[Output]        {x.shape}\")\n\n        return x\n# 1. Create an instance of your model\nmodel = SafetyCNN()\n\n# 2. Create a dummy input to test the model\n# Shape: [1, 3, 224, 224] ‚Üí batch of 1 image, 3 channels (RGB), 224x224\ndummy_input = torch.randn(1, 3, 224, 224)\n\n# 3. Pass the dummy input through the model\noutput = model(dummy_input)\n\n# CNN model for multi-label classification of safety gear in images.\n# Input: RGB image of size [3, 224, 224]\n# Output: 6 probabilities (one for each label: person, red_hat, etc.)\n\n# Model structure:\n# - Conv2d + ReLU + MaxPool: learns low-level features (edges, shapes)\n# - Repeated 3 times with more filters to learn complex patterns\n# - Flatten: turns feature maps into a long vector\n# - Linear: fully connected layer outputs 6 scores\n# - Sigmoid: converts scores into probabilities for each label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:40:16.422167Z","iopub.execute_input":"2025-07-16T20:40:16.422483Z","iopub.status.idle":"2025-07-16T20:40:16.558554Z","shell.execute_reply.started":"2025-07-16T20:40:16.422454Z","shell.execute_reply":"2025-07-16T20:40:16.557595Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_dataset = SafetyDataset(train_df, '/kaggle/working/resized_images', train_labels, transform=transform)\nval_dataset   = SafetyDataset(val_df,   '/kaggle/working/resized_images', val_labels,   transform=transform)\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\nimport torch.optim as optim\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\ncriterion = nn.BCELoss()  # Binary Cross Entropy for multi-label classification\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 10\nbest_val_loss=float('inf')\npatience=2\ncounter=0\nfor epoch in range(num_epochs):  # You can define num_epochs above\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        outputs = model(images)\n        loss = criterion(outputs, labels.float())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    avg_loss = running_loss / len(train_loader)\n\n    \n    # --- Validation ---\n\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            outputs = model(images)\n            loss = criterion(outputs, labels.float())\n            val_loss += loss.item()\n    avg_val_loss = val_loss / len(val_loader)\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f} - Val Loss: {avg_val_loss:.4f}\")\n\n    #early stopping\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        counter = 0\n        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n    else:\n        counter += 1\n        if counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:40:16.559456Z","iopub.execute_input":"2025-07-16T20:40:16.559770Z","iopub.status.idle":"2025-07-16T20:48:10.403351Z","shell.execute_reply.started":"2025-07-16T20:40:16.559747Z","shell.execute_reply":"2025-07-16T20:48:10.402328Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Train Loss: 0.5305 - Val Loss: 0.4914\nEpoch [2/10] - Train Loss: 0.4750 - Val Loss: 0.4309\nEpoch [3/10] - Train Loss: 0.4352 - Val Loss: 0.4279\nEpoch [4/10] - Train Loss: 0.4087 - Val Loss: 0.4145\nEpoch [5/10] - Train Loss: 0.3950 - Val Loss: 0.4104\nEpoch [6/10] - Train Loss: 0.3749 - Val Loss: 0.4112\nEpoch [7/10] - Train Loss: 0.3529 - Val Loss: 0.3954\nEpoch [8/10] - Train Loss: 0.3322 - Val Loss: 0.3975\nEpoch [9/10] - Train Loss: 0.3066 - Val Loss: 0.3981\nEarly stopping triggered.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Define the test dataset\ntest_dataset = SafetyDataset(test_df, '/kaggle/working/resized_images', test_labels, transform=transform)\n\n# Create the test DataLoader\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Load the best model\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\n\n# Test the model on the test dataset\ncorrect_predictions = 0\ntotal_labels = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        outputs = model(images)\n        preds = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n        correct_predictions += (preds == labels).sum().item()\n        total_labels += labels.numel()\n        \n# Calculate accuracy\ntest_accuracy = (correct_predictions / total_labels) * 100\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:48:10.404399Z","iopub.execute_input":"2025-07-16T20:48:10.404762Z","iopub.status.idle":"2025-07-16T20:48:15.312096Z","shell.execute_reply.started":"2025-07-16T20:48:10.404732Z","shell.execute_reply":"2025-07-16T20:48:15.310825Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 80.53%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from torchvision import transforms\n\n# üîß Define test transform with resizing\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # üëà Resize all test images to 224x224\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\n# üìÇ Test image directory\ntest_dir = '/kaggle/input/draft-safety/test_safety/test_safety'\n\n# üßæ List of test image file names\ntest_filenames = sorted([f for f in os.listdir(test_dir) if f.endswith('.jpg')])\ntest_df = pd.DataFrame({'image_id': [f.replace('.jpg', '') for f in test_filenames]})\n\n# üß† Create test dataset and loader\ntest_dataset = SafetyDataset(test_df, test_dir, labels=[[0]*6]*len(test_df), transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# üîç Run inference\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for images, _ in test_loader:\n        outputs = model(images)\n        preds = (outputs > 0.5).int().tolist()\n        predictions.extend(preds)\n\n# üìù Prepare submission file\nsubmission = pd.DataFrame()\nsubmission['image_id'] = test_df['image_id']\nsubmission['labels'] = [' '.join([label for i, label in enumerate(all_labels) if p[i]]) for p in predictions]\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"‚úÖ submission.csv ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T21:42:12.126558Z","iopub.execute_input":"2025-07-16T21:42:12.127033Z","iopub.status.idle":"2025-07-16T21:42:26.935035Z","shell.execute_reply.started":"2025-07-16T21:42:12.127003Z","shell.execute_reply":"2025-07-16T21:42:26.934109Z"}},"outputs":[{"name":"stdout","text":"‚úÖ submission.csv ready!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport os\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:48:32.488374Z","iopub.execute_input":"2025-07-16T20:48:32.488696Z","iopub.status.idle":"2025-07-16T20:48:32.494056Z","shell.execute_reply.started":"2025-07-16T20:48:32.488672Z","shell.execute_reply":"2025-07-16T20:48:32.492904Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"resnet50 = models.resnet50(weights=None)\nstate_dict = torch.load(\"/kaggle/input/resnet/pytorch/default/1/resnet50-11ad3fa6.pth\")\nresnet50.load_state_dict(state_dict)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:48:32.494962Z","iopub.execute_input":"2025-07-16T20:48:32.495236Z","iopub.status.idle":"2025-07-16T20:48:34.191802Z","shell.execute_reply.started":"2025-07-16T20:48:32.495206Z","shell.execute_reply":"2025-07-16T20:48:34.190595Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# ‚úÖ Step 1: Get input size before replacing\nnum_features = resnet50.fc.in_features\n\n# ‚úÖ Step 2: Freeze pretrained layers\nfor param in resnet50.parameters():\n    param.requires_grad = False\n\n# ‚úÖ Step 3: Replace classifier\nresnet50.fc = nn.Sequential(\n    nn.Linear(num_features, 6),\n    nn.Sigmoid()\n)\n#load and prepare the data for resnet , edit is so it would be as resnet expect it \ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406], \n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:48:34.192677Z","iopub.execute_input":"2025-07-16T20:48:34.193020Z","iopub.status.idle":"2025-07-16T20:48:34.201902Z","shell.execute_reply.started":"2025-07-16T20:48:34.192998Z","shell.execute_reply":"2025-07-16T20:48:34.200393Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#training the final layers of the model\ncriterion = nn.BCELoss()  # Multi-label = Binary Cross Entropy\noptimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)\ntrain_dataset = SafetyDataset(train_df, '/kaggle/working/resized_images', train_labels, transform=transform)\nval_dataset   = SafetyDataset(val_df,   '/kaggle/working/resized_images', val_labels,   transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nnum_epochs = 10\nbest_val_loss = float('inf')\npatience = 2\ncounter = 0\n\nfor epoch in range(num_epochs):\n    resnet50.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        outputs = resnet50(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    avg_train_loss = running_loss / len(train_loader)\n\n    # Validation\n    resnet50.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            outputs = resnet50(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n    avg_val_loss = val_loss / len(val_loader)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        counter = 0\n        torch.save(resnet50.state_dict(), 'best_resnet50.pth')\n    else:\n        counter += 1\n        if counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T20:48:34.203130Z","iopub.execute_input":"2025-07-16T20:48:34.203507Z","iopub.status.idle":"2025-07-16T21:32:20.729222Z","shell.execute_reply.started":"2025-07-16T20:48:34.203472Z","shell.execute_reply":"2025-07-16T21:32:20.728100Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Train Loss: 0.5208 - Val Loss: 0.4640\nEpoch [2/10] - Train Loss: 0.4393 - Val Loss: 0.4269\nEpoch [3/10] - Train Loss: 0.3994 - Val Loss: 0.4012\nEpoch [4/10] - Train Loss: 0.3756 - Val Loss: 0.3854\nEpoch [5/10] - Train Loss: 0.3515 - Val Loss: 0.3734\nEpoch [6/10] - Train Loss: 0.3337 - Val Loss: 0.3640\nEpoch [7/10] - Train Loss: 0.3178 - Val Loss: 0.3574\nEpoch [8/10] - Train Loss: 0.3003 - Val Loss: 0.3467\nEpoch [9/10] - Train Loss: 0.2875 - Val Loss: 0.3450\nEpoch [10/10] - Train Loss: 0.2772 - Val Loss: 0.3328\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Load the best resnet50 model\nresnet50.load_state_dict(torch.load('best_resnet50.pth'))\nresnet50.eval()\n\ncorrect_predictions = 0\ntotal_labels = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        outputs = resnet50(images)\n        preds = (outputs > 0.5).float()\n        correct_predictions += (preds == labels).sum().item()\n        total_labels += labels.numel()\n\ntest_accuracy = (correct_predictions / total_labels) * 100\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T21:34:30.009335Z","iopub.execute_input":"2025-07-16T21:34:30.009755Z","iopub.status.idle":"2025-07-16T21:35:35.418184Z","shell.execute_reply.started":"2025-07-16T21:34:30.009724Z","shell.execute_reply":"2025-07-16T21:35:35.417274Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 63.04%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from torchvision import transforms\n\n# üîß Define test transform with ResNet normalization\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],  # ResNet expected mean\n        std=[0.229, 0.224, 0.225]    # ResNet expected std\n    )\n])\n\n# üìÇ Test image directory\ntest_dir = '/kaggle/input/draft-safety/test_safety/test_safety'\n\n# üßæ List of test image file names\ntest_filenames = sorted([f for f in os.listdir(test_dir) if f.endswith('.jpg')])\ntest_df = pd.DataFrame({'image_id': [f.replace('.jpg', '') for f in test_filenames]})\n\n# üß† Create test dataset and loader\ntest_dataset = SafetyDataset(test_df, test_dir, labels=[[0]*6]*len(test_df), transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# üîç Run inference with resnet50\nresnet50.eval()\npredictions = []\n\nwith torch.no_grad():\n    for images, _ in test_loader:\n        outputs = resnet50(images)\n        preds = (outputs > 0.5).int().tolist()\n        predictions.extend(preds)\n\n# üìù Prepare submission file\nsubmission = pd.DataFrame()\nsubmission['image_id'] = test_df['image_id']\nsubmission['labels'] = [' '.join([label for i, label in enumerate(all_labels) if p[i]]) for p in predictions]\nsubmission.to_csv('submission1.csv', index=False)\n\nprint(\"‚úÖ submission1.csv ready with ResNet50!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T21:42:26.936564Z","iopub.execute_input":"2025-07-16T21:42:26.936845Z","iopub.status.idle":"2025-07-16T21:43:31.666825Z","shell.execute_reply.started":"2025-07-16T21:42:26.936822Z","shell.execute_reply":"2025-07-16T21:43:31.664960Z"}},"outputs":[{"name":"stdout","text":"‚úÖ submission1.csv ready with ResNet50!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"for name, param in resnet50.named_parameters():\n    if \"layer4\" in name or \"fc\" in name:\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T21:58:43.985709Z","iopub.execute_input":"2025-07-16T21:58:43.986029Z","iopub.status.idle":"2025-07-16T21:58:43.992146Z","shell.execute_reply.started":"2025-07-16T21:58:43.986010Z","shell.execute_reply":"2025-07-16T21:58:43.991203Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"optimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, resnet50.parameters()),\n    lr=0.001\n)\n#training the final layers of the model\ncriterion = nn.BCELoss()  # Multi-label = Binary Cross Entropy\noptimizer = torch.optim.Adam(resnet50.fc.parameters(), lr=0.001)\ntrain_dataset = SafetyDataset(train_df, '/kaggle/working/resized_images', train_labels, transform=transform)\nval_dataset   = SafetyDataset(val_df,   '/kaggle/working/resized_images', val_labels,   transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nnum_epochs = 20\nbest_val_loss = float('inf')\npatience = 2\ncounter = 0\n\nfor epoch in range(num_epochs):\n    resnet50.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        outputs = resnet50(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    avg_train_loss = running_loss / len(train_loader)\n\n    # Validation\n    resnet50.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            outputs = resnet50(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n    avg_val_loss = val_loss / len(val_loader)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}\")\n\n    # Early stopping\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        counter = 0\n        torch.save(resnet50.state_dict(), 'best_resnet50_two.pth')\n    else:\n        counter += 1\n        if counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T22:35:56.427732Z","iopub.execute_input":"2025-07-16T22:35:56.428663Z","iopub.status.idle":"2025-07-16T22:49:51.368364Z","shell.execute_reply.started":"2025-07-16T22:35:56.428623Z","shell.execute_reply":"2025-07-16T22:49:51.366882Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20] - Train Loss: 0.2006 - Val Loss: 0.2945\nEpoch [2/20] - Train Loss: 0.1975 - Val Loss: 0.2957\nEpoch [3/20] - Train Loss: 0.1895 - Val Loss: 0.2953\nEarly stopping triggered.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Load the best resnet50 model\nresnet50.load_state_dict(torch.load('best_resnet50_two.pth'))\nresnet50.eval()\n\ncorrect_predictions = 0\ntotal_labels = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        outputs = resnet50(images)\n        preds = (outputs > 0.5).float()\n        correct_predictions += (preds == labels).sum().item()\n        total_labels += labels.numel()\n\ntest_accuracy = (correct_predictions / total_labels) * 100\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T22:50:55.733311Z","iopub.execute_input":"2025-07-16T22:50:55.734780Z","iopub.status.idle":"2025-07-16T22:51:59.395946Z","shell.execute_reply.started":"2025-07-16T22:50:55.734741Z","shell.execute_reply":"2025-07-16T22:51:59.394179Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 61.38%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from torchvision import transforms\n\n# üîß Define test transform with ResNet normalization\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],  # ResNet expected mean\n        std=[0.229, 0.224, 0.225]    # ResNet expected std\n    )\n])\n\n# üìÇ Test image directory\ntest_dir = '/kaggle/input/draft-safety/test_safety/test_safety'\n\n# üßæ List of test image file names\ntest_filenames = sorted([f for f in os.listdir(test_dir) if f.endswith('.jpg')])\ntest_df = pd.DataFrame({'image_id': [f.replace('.jpg', '') for f in test_filenames]})\n\n# üß† Create test dataset and loader\ntest_dataset = SafetyDataset(test_df, test_dir, labels=[[0]*6]*len(test_df), transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# üîç Run inference with resnet50\nresnet50.eval()\npredictions = []\n\nwith torch.no_grad():\n    for images, _ in test_loader:\n        outputs = resnet50(images)\n        preds = (outputs > 0.5).int().tolist()\n        predictions.extend(preds)\n\n# üìù Prepare submission file\nsubmission = pd.DataFrame()\nsubmission['image_id'] = test_df['image_id']\nsubmission['labels'] = [' '.join([label for i, label in enumerate(all_labels) if p[i]]) for p in predictions]\nsubmission.to_csv('submission2.csv', index=False)\n\nprint(\"‚úÖ submission1.csv ready with ResNet50!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T22:53:21.817471Z","iopub.execute_input":"2025-07-16T22:53:21.818463Z","iopub.status.idle":"2025-07-16T22:54:24.251305Z","shell.execute_reply.started":"2025-07-16T22:53:21.818432Z","shell.execute_reply":"2025-07-16T22:54:24.249925Z"}},"outputs":[{"name":"stdout","text":"‚úÖ submission1.csv ready with ResNet50!\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}